Self-Improver 루프 고도화와 온톨로지 기반 추천 시스템 강화를 목표로, OpenAI의 최신 모델 5종을 기준으로 하는 1인 개발자용 AI 프로젝트 확장 구현 계획서

계획서는 AI 에이전트가 단독으로 구현할 수 있도록 작성되며, 로컬 중심 구조와 확장성 높은 아키텍처, 반복적 개선과 실시간 분석을 고려한 설계 원칙에 기반합니다. 완료되면 문서 형식으로 공유드리겠습니다.


# Palantir.Zip 에이전트 플랫폼 구현 계획서

## 설계 원칙 및 시스템 개요

Palantir.Zip은 1인 개발자가 로컬 환경에서 사용하는 멀티에이전트 기반 AI 자동화 플랫폼입니다. 본 계획서는 **Self-Improver 루프**와 **온톨로지 기반 추천 시스템**을 고도화하는 구현 지침을 제시합니다. 모든 기능은 **확장성**과 **변경 용이성**을 고려하여 구조적으로 모듈화합니다. 각 구성 요소는 독립적인 모듈이나 에이전트로 구현하고, 상호 작용은 명확한 인터페이스를 통해 이루어지도록 설계합니다.

특히 LLM 활용에 있어 OpenAI 계열 5종 모델(GPT-4o, o3, o3-pro, o4-mini, o4-mini-high)을 상황별로 적절히 조합하여 사용합니다. 모델별 역할 분담을 통해 응답 시간과 비용을 최적화하면서도 정확도를 확보합니다:

* **GPT-4o** – 최고 성능의 모델로, 복잡한 분석이나 중요한 결정을 내리는 **리더/플래너 에이전트** 역할을 맡깁니다. 코드 베이스 전체 구조 파악, 어려운 디버깅, 종합적인 Q\&A 답변 생성 등에 활용합니다.
* **GPT-o3** – 비교적 가벼운 모델로, **코드 생성 및 일반적인 분석 작업**에 사용합니다. 간단한 함수 수정이나 요약 등에는 이 모델을 우선 적용하여 속도를 높입니다.
* **GPT-o3-pro** – o3의 향상된 버전으로, **코드 작성 및 리팩토링 제안** 등 중간 난이도의 작업에 투입합니다. o3보다 고품질 출력이 필요하지만 GPT-4o 만큼 리소스가 필요하지 않은 작업에 활용합니다.
* **GPT-o4-mini** – 경량화된 GPT-4 계열 모델로, **단순 분류나 예/아니오 결정 등 보조적인 작업**에 사용합니다. 예를 들어 테스트 로그에서 간단한 패턴을 분류하거나, 요약된 정보에서 True/False 판단을 내릴 때 사용합니다.
* **GPT-o4-mini-high** – mini 모델의 상위 버전으로, **중간 복잡도의 추론 작업**에 투입합니다. GPT-4oほど 무겁진 않지만 mini보다는 뛰어난 성능이 필요한 경우(예: 다소 복잡한 원인 분석이나 간단한 Q\&A 답변)에 활용합니다.

이러한 모델들을 멀티에이전트 구조 하에서 **LangGraph**를 활용해 오케스트레이션합니다. LangGraph를 사용하면 에이전트 간 상태 공유와 **조건부 분기** 및 **사이클(loop)** 제어가 용이하여, Self-Improver 루프의 반복 제어나 추천 시스템의 질의응답 흐름을 유연하게 구현할 수 있습니다. 각 에이전트는 LangGraph의 노드로 구성하고, 에이전트 간 데이터는 공유 상태(`GraphState`)나 메시지를 통해 전달합니다. 주요 에이전트(노드) 구성은 다음과 같습니다:

* **오케스트레이터**: 전체 흐름을 통제하는 상위 에이전트로, 각 단계별 에이전트를 호출하고 종료 조건을 관리합니다. LangGraph에서 그래프의 `START`와 `END`를 연결하며, 분기 로직을 통해 루프 진행이나 중단을 결정합니다.
* **코드 분석/개선 플래너**: Self-Improver 루프에서 코드와 테스트 결과를 분석하고 수정 계획을 수립하는 에이전트입니다. GPT-4o와 GPT-o3-pro를 주로 활용하며, 원인 분석 및 해결 전략 수립을 담당합니다.
* **코드 수정 실행자**: 플래너의 지시에 따라 실제 코드 변경을 수행하는 에이전트입니다. GPT-o3나 GPT-o3-pro를 사용해 구체적인 코드 패치를 생성합니다.
* **테스트 실행/평가기**: Pytest를 통해 코드를 테스트하고 결과를 수집하는 모듈(툴)입니다. LLM이 아닌 Python 함수를 LangGraph 도구로 등록하여, 지정된 테스트 스위트를 실행하고 결과를 상태에 기록합니다.
* **오류 진단 에이전트**: 실패한 테스트 결과 로그를 분석하여 원인을 추론하고 해결 방향을 제안하는 에이전트입니다. GPT-o4-mini-high나 GPT-4o를 사용해 심층적인 원인 분석을 수행합니다.
* **리팩토링 제안자**: 코드가 일단 동작하는 상태가 되면, 구조적 개선이나 최적화를 제안하는 에이전트입니다. GPT-o3-pro나 GPT-4o를 활용하여 코드 품질 향상을 위한 리팩토링 방안을 도출합니다.
* **온톨로지 질의응답 에이전트**: 사용자의 질의에 대해 지식 그래프와 벡터 DB를 활용하여 답변하거나 관련 정보를 추천하는 에이전트입니다. GPT-4o는 답변 생성에, GPT-o3는 간단한 추천 리스트 작성 등에 활용됩니다.

이하에서는 두 가지 핵심 기능( Self-Improver 루프, 온톨로지 기반 추천 시스템)에 대해 단계별 구현 지침을 상세히 다룹니다. 각 기능은 **FastAPI** 기반의 API 엔드포인트 혹은 내부 모듈로 제공되며, Pydantic 모델로 데이터 구조를 정의하고 Pytest로 검증 가능합니다.

## Self-Improver 루프 고도화

Self-Improver 루프는 \*“코드 분석 → 테스트 → 개선 → 재평가”\*를 자동으로 반복하여 코드베이스를 지속적으로 향상시키는 기능입니다. 이를 고도화하기 위해 **테스트 실패 시 자동 원인 분석**, **롤백 및 분기 처리**, **리팩토링 제안**, **개선 반복 및 안전 중단**까지 포괄하는 높은 신뢰도의 루프를 구현합니다. 구현은 LangGraph를 이용한 에이전트 workflow로 구성하고, 각 단계는 모듈화하여 설계합니다. 아래에 단계별 세부 구현 지침을 제시합니다.

### 1. 코드 및 테스트 분석 (Analyzer 에이전트)

**역할**: 현재 코드 상태와 테스트 상황을 파악하고, 실패 원인이나 개선 방향을 계획합니다. 이 에이전트는 루프의 첫 단계로서, 이전 반복에서 실패한 테스트가 있거나 신규 이슈가 발견된 경우 이를 분석합니다.

* **입력**: 소스 코드 베이스(파일 내용 또는 경로), 실패한 테스트 목록 및 오류 로그(직전 테스트 실행 결과), 이전 반복의 상태 정보(예: 이전 수정 내용, 시도 횟수 등).
* **처리**:

  * 만약 첫 반복이거나 새로운 실패가 발생했다면, GPT-4o 모델을 사용하여 코드 전반과 실패 로그를 검토하고 **문제 원인**을 추론합니다. 예를 들어, 오류 메시지나 스택트레이스를 토대로 어떤 함수나 모듈에서 문제가 생겼는지 원인을 파악합니다. 최신 연구에서도 GPT-4 모델의 **자기 오류 성찰(reflection)** 능력을 활용하면 성능이 크게 향상됨이 보고되었으므로, GPT-4o에게 \*\*"오류 원인을 설명하고 수정 계획을 단계별로 제시"\*\*하도록 프롬프트를 구성합니다.
  * 원인 분석 결과에는 다음과 같은 정보를 포함시킵니다:

    * 문제를 일으킨 원인의 요약 (자연어 설명).
    * 문제 발생 지점(해당 소스 파일의 위치나 함수명 등).
    * 수정 방향에 대한 제안 (어떤 부분을 어떻게 변경해야 할지).
    * 만약 근본적 구조 문제가 의심된다면 리팩토링 필요 여부.
  * 이 출력을 **구조화된 형식**으로 받도록 합니다. LangChain의 Structured Output이나 Pydantic BaseModel을 활용하여 모델이 JSON 형태로 답하도록 유도하면 신뢰도를 높일 수 있습니다. 예를 들어 아래와 같은 Pydantic 모델을 정의합니다:

    ```python
    class AnalysisResult(BaseModel):
        cause: str  # 오류 원인 요약
        target_file: str  # 문제 발생 파일 또는 컴포넌트
        suggestion: str  # 제안하는 수정 방향
        refactor_needed: bool  # 큰 리팩토링이 필요한지 여부
    ```

    프롬프트 예시:

    ```
    시스템: 당신은 AI 소프트웨어 분석가입니다. 주어진 코드와 테스트 실패 로그를 바탕으로 버그 원인을 분석하고 수정 계획을 JSON으로 출력하세요.
    사용자 입력:
    코드 발췌: {문제 추정 위치의 코드}
    테스트 오류: {오류 메시지 및 스택트레이스}
    요구: {"cause": ..., "target_file": ..., "suggestion": ..., "refactor_needed": ...} 형태로 답변
    ```
  * GPT-4o가 분석을 수행하고, **AnalysisResult** 객체로 결과를 반환하면 이를 상태에 저장합니다. 만약 사소한 버그처럼 보이는 경우 refactor\_needed를 False로, 설계 결함이나 중복코드 등 근본 개선이 필요하면 True로 표시하게 합니다.
* **모델 선택**:

  * 초기 원인 분석에는 정확성이 중요하므로 **GPT-4o**를 우선 사용합니다.
  * 다만 문제 복잡도가 낮거나 단순한 실패(예: 문법 에러 등)는 비용 절감을 위해 **GPT-o3-pro**로도 충분히 처리 가능하니, 오류 유형에 따라 모델을 스위칭하는 최적화도 고려합니다 (예: SyntaxError 같은 키워드가 로그에 있으면 작은 모델 사용).
* **출력**: AnalysisResult 데이터 (원인 및 수정 제안). 추후 단계에서 이 정보를 바탕으로 코드 수정이 이루어집니다.

### 2. 코드 수정 및 개선 (Code Editor 에이전트)

**역할**: Analyzer에서 제시한 수정 방향(패치 제안)을 실제 코드 변경으로 구현합니다. 이 단계에서는 LLM이 코드 생성을 담당하며, 제안된 해결책을 구체적인 코드로 변환합니다.

* **입력**: 이전 단계의 **AnalysisResult** (문제가 된 파일/함수와 수정 제안), 그리고 기존 소스 코드 내용.
* **처리**:

  * 대상 파일이나 함수의 최신 코드를 불러와서, **GPT-o3-pro** 또는 **GPT-o3** 모델을 이용해 제안에 따른 수정 코드를 생성합니다. 프롬프트 예시:

    ```
    시스템: 당신은 AI 코드 생성기입니다. 제시된 지침에 따라 코드 변경을 수행하세요.
    사용자 입력:
    파일 경로: {target_file}
    기존 코드:
    ```

    ```python
    {소스 코드 내용}
    ```

    ```
    수정 지시: {suggestion 내용}
    요구: 변경된 파일의 완전한 코드만 출력
    ```
  * 모델이 수정된 전체 파일 코드를 출력하도록 유도하거나, **diff 패치 형태**로 출력을 유도할 수 있습니다. 완전한 코드 출력을 받으면 그대로 파일을 덮어쓰고, diff 형태로 받으면 patch를 적용하는 로직을 구현합니다. 완전한 코드 출시는 간단하지만 파일이 큰 경우 맥락 길이 한계에 부딪힐 수 있으므로, **부분 수정이 필요한 범위만 맥락에 포함**시키는 최적화가 필요합니다 (예: 문제 함수만 발췌하여 맥락으로 제공).
  * LangChain을 사용할 경우, 프롬프트를 `ChatPromptTemplate`으로 구성하고 모델에 `with_structured_output` 대신 **코드 블록 형식**으로 출력하도록 유도할 수 있습니다. 예를 들어, 모델 답변에 markdown 코드 블록으로 변경된 코드만 담도록 지시하여 추출 및 파일 기록을 단순화합니다.
  * **코드 생성 검증**: 생성된 코드가 syntax error가 없는지 간단한 검증을 합니다. Python의 `ast.parse` 등을 이용하여 구문 검사를 하고, 오류가 있다면 곧바로 작은 모델(**GPT-o4-mini**)을 통해 수정하거나, 필요 시 GPT-o3-pro에게 재수정을 요청합니다. 이러한 1차 검증을 통해 명백한 문법 오류는 루프에 들어가기 전에 걸러냅니다.
* **모델 선택**: 코드 생성은 **GPT-o3-pro**를 기본으로 하나, 변경 범위가 작고 단순한 경우 **GPT-o3**도 활용합니다. 복잡한 알고리즘 수정이나 타 시스템과의 연계 등 큰 변경은 **GPT-4o**에게 맡겨 정확도를 높일 수 있습니다. (플래너가 refactor\_needed=True로 표시한 경우, 이후 리팩토링 단계에서 GPT-4o를 활용할 예정이므로 여기서는 제안된 부분 수정에 집중합니다.)
* **출력**: 갱신된 소스 코드 (파일들이 수정됨). 변경된 파일들은 임시 디렉토리에 저장하거나 Git 분기에 커밋하여, 테스트 실패 시 롤백할 수 있도록 준비해둡니다 (자세한 롤백 전략은 아래 단계에서 설명).

### 3. 테스트 실행 및 결과 수집 (Tester 모듈)

**역할**: 수정된 코드에 대해 **Pytest**를 자동 실행하고, 테스트 결과(성공/실패 여부와 로그)를 수집합니다. 이 단계는 LangGraph 내에서 도구(tool) 노드로 구현하거나, Orchestrator에서 직접 함수 호출로 처리할 수 있습니다.

* **처리**:

  * Python의 `pytest` 모듈이나 `subprocess`를 통해 테스트 스위트를 실행합니다.
  * 예를 들어 `pytest.main(["-q", "--maxfail=1", "--disable-warnings"])`와 같은 호출로 테스트를 실행하고, 결과를 프로그램matically 수집할 수 있습니다. 또는 `subprocess.run(["pytest", "-q"], capture_output=True)`를 사용하여 표준출력에 나타난 실패 로그를 확보합니다.
  * Pytest에서 제공하는 `TestReport` 객체를 활용하면 어떤 테스트 케이스들이 실패했는지, 어떤 에러가 발생했는지 추출할 수 있습니다. 필요하다면 `pytest --json-report` 플러그인을 사용하여 JSON 형식의 결과를 얻고 파싱할 수도 있습니다.
  * 테스트 실행 결과는 **상태**에 기록합니다. 예를 들어 `state["test_passed"] = False`, `state["failures"] = [...]` (실패한 테스트 목록), `state["log"] = "..."` (전체 실패 로그 텍스트) 등을 저장합니다.

* **오류 로그 정리**: 추후 LLM에 전달하기 위해 실패 로그에서 불필요한 부분(예: 장황한 Traceback 중 프레임 주소 등)을 필터링합니다. 핵심은 **AssertionError 메시지, Exception 타입 및 메시지, 실패한 테스트 이름** 등 원인 분석에 필요한 정보를 포함하는 것입니다. 이 부분을 전처리하여 깨끗한 로그를 준비합니다.

* **모델 사용**: 이 단계 자체는 코드 실행이므로 LLM은 사용하지 않습니다. 다만, 테스트 결과 요약이나 실패한 케이스 수를 LLM에 전달할 때 **자연어 요약**이 필요하면 GPT-o4-mini 등을 써서 `"전체 10개 중 2개 테스트 실패: test_example1 실패 - AssertionError ..."` 식으로 요약문을 만들 수 있습니다. 그러나 보통 원문 로그를 그대로 원인 분석 에이전트에 주어도 충분합니다.

* **출력**: 테스트 성공 여부(boolean), 실패 시 실패 내용(log 또는 구조화 정보). 이 결과에 따라 다음 분기(성공 시 루프 종료, 실패 시 원인분석으로 재진입)를 결정합니다.

### 4. 실패 원인 자동 분석 및 롤백 결정 (Diagnostics & Rollback)

**역할**: 테스트가 실패한 경우, **오류 원인**을 신속히 분석하고 다음 조치를 결정합니다. 또한, 특정 조건에서 **코드 롤백**(이전 안정 상태로 복귀)을 수행합니다. 이 단계는 Analyzer 에이전트와 긴밀히 연계되며, 실패 유형에 따른 **상태 기반 분기**를 처리합니다.

* **입력**: Tester에서 수집한 실패 정보(로그, 실패한 테스트 목록), 그리고 현재까지의 수정 이력이나 시도 횟수 등의 상태.
* **처리**:

  1. **자동 원인 재분석**: 처음 루프 진입 시 수행했던 분석과 유사하게, GPT-o4-mini-high 모델로 **오류 로그에 대한 신속 진단**을 수행합니다. 만약 이전 AnalysisResult가 이미 있다면, 해당 원인이 제대로 해결되지 않은 것이므로 **이전 원인과 현재 로그를 함께** 모델에게 제공해 무엇이 부족했는지 평가하도록 합니다. 작은 모델로 빠르게 원인을 재확인하고, 필요시 GPT-4o로 심층 분석 재시도합니다.
  2. **해결 전략 분기**: 실패 상황에 따라 분기합니다:

     * **동일한 테스트가 반복 실패**: 이전과 같은 오류가 지속된다면, 이전 수정이 효과가 없었던 것입니다. 이 경우 GPT-4o를 투입해 **해결 전략을 재고**합니다. 보다 근본적인 접근(다른 영역 수정 or 리팩토링)을 모색하고, 필요하면 refactor\_needed 플래그를 True로 변경합니다.
     * **새로운 실패가 발생**: 수정 후 새로운 테스트가 실패했다면, 수정 과정에서 부작용이 발생한 것입니다. 이 경우 **롤백**을 고려합니다. 변경으로 인한 부작용이 크다고 판단되면, 수정 전에 백업해둔 원본 코드로 롤백하고 다른 접근을 시도합니다. 롤백 여부 판단은 실패한 테스트의 수와 범위로 결정합니다. 예를 들어, 원래 1개의 실패만 있었는데 수정 후 3개의 테스트가 새로 실패했다면 **즉시 롤백**하는 것이 안전합니다. 반면 기존 실패가 계속되고 추가 실패는 없다면 롤백하지 않고 재시도합니다.
     * **구문 에러 등 치명적 실패**: 만약 LLM이 작성한 코드에 치명적인 오류(예: 애플리케이션 크래시, 테스트 자체 실행 불가)가 발생하면, 해당 수정은 적용하지 않고 **무조건 롤백**합니다. 그런 다음 더 높은 성능 모델로 재생성하거나, 단계적으로 코드를 수정하는 전략이 필요합니다.
  3. **롤백 구현**: 롤백이 결정되면, 코드 베이스를 이전 상태로 되돌립니다. 이는 Git을 사용하면 간편합니다. 구현 단계에서:

     * 시작 시점에 전체 코드베이스 스냅샷을 저장하거나 Git 커밋을 만들어 둡니다.
     * 각 수정 전에도 커밋 또는 백업 파일을 생성합니다.
     * 롤백 시 해당 커밋을 `git reset --hard`로 checkout하거나, 백업 파일을 덮어씁니다.
     * 롤백이 일어났음을 상태에 기록하고, 이후 다른 접근으로 다시 수정 시도를 이어갑니다.
  4. **시도 횟수 및 중단 판단**: 상태에 현재까지 루프 반복 횟수를 기록하고, 일정 임계치를 넘으면 안전 중단합니다. 예를 들어 5회 이상 시도해도 해결 못 하면 자동 중단하도록 설정합니다. 중단 시에는 마지막 안정 버전(통과했던 버전)으로 코드를 유지하고, 사용자에게 실패 원인과 향후 권고(예: 인간의 개입 필요)를 제시하도록 에이전트에게 안내합니다.
* **모델 선택**: 원인 재분석과 분기 결정에는 **GPT-o4-mini-high**로 충분히 가능하지만, 상황에 따라 GPT-4o의 판단을 받는 것이 좋습니다. 특히 “롤백 후 다른 접근 시도”와 같은 중요한 분기에서는 GPT-4o로 하여금 *"다른 어떤 부분을 수정해야 통과할지"* 계획을 다시 세우도록 합니다. 반면 롤백 여부 결정은 규칙 기반(정형화된 로직)으로 구현하는 편이 확실하므로, 코드 수준에서 `if` 문으로 처리합니다.
* **출력**: 다음 액션에 대한 결정:

  * 수정 반복을 계속할지 여부 (`continue_loop`: True/False).
  * 롤백 수행 여부 (`did_rollback`: True/False).
  * 업데이트된 AnalysisResult (필요 시 원인/제안 수정).
  * 루프 중단 여부 (`abort`: True/False, 안전 중단 플래그).

이 정보를 Orchestrator가 받아서, **continue\_loop가 True**이면 **2. 코드 수정 단계**로 돌아가고 (LangGraph에서는 conditional edge로 START 지점 또는 수정 노드로 되돌아가는 사이클을 구성), **abort가 True**이면 루프를 종료합니다.

### 5. 반복 개선 사이클 및 안전 중단

위 단계들을 통해 루프 구조를 완성합니다. LangGraph를 사용하면 아래와 같은 형태로 그래프를 구성할 수 있습니다 (의사 코드):

```python
workflow = StateGraph()
workflow.add_node("analyze_code", analyze_code_node)        # 코드/테스트 분석
workflow.add_node("apply_patch", apply_patch_node)          # 코드 수정 적용
workflow.add_node("run_tests", run_tests_node)              # 테스트 실행
workflow.add_node("diagnose", diagnose_node)                # 실패 진단 및 분기 처리

workflow.add_edge(START, "analyze_code")
workflow.add_edge("analyze_code", "apply_patch")
workflow.add_edge("apply_patch", "run_tests")
# 테스트 결과에 따라 분기: 성공이면 종료, 실패면 diagnose로
workflow.add_conditional_edges(
    "run_tests",
    lambda state: "diagnose" if state.get("test_passed") is False else END,
    {"diagnose": "diagnose", END: END}
)
# diagnose 후 분기: 계속 반복 또는 중단
workflow.add_conditional_edges(
    "diagnose",
    route_diagnose_edge,  # 상태 기반 분기 함수 구현
    {
        "apply_patch": "apply_patch",  # 개선 계속
        END: END                      # 중단 또는 완료
    }
)
```

위 `route_diagnose_edge` 함수에서는 `state`를 검사하여 **계속 진행**인지 **END로 종료**인지 경로를 결정합니다. 예를 들어 `state["continue_loop"]`가 True이고 `state["abort"]`가 False이면 `"apply_patch"`로 분기, 그렇지 않으면 END로 분기하도록 구현합니다.

**안전 중단**은 `state["abort"]`를 True로 설정함으로써 실현됩니다. Abort가 True인 경우에는 더 이상 수정 시도 없이 루프를 종료하며, Orchestrator는 최종적으로 \*\*"자동 개선 작업을 중단했다"\*\*는 메시지와 현재까지의 최선 결과를 요약해줄 수 있습니다.

* **상태 관리**: 시도 횟수(`attempt_count`), 마지막 실패 종류(`last_error_type`) 등을 상태에 저장하여 분기에 활용합니다. 예를 들어 `attempt_count >= MAX_TRIES`이면 abort를 True로 설정합니다.
* **로그 및 투명성**: 루프가 진행되는 동안 각 단계의 결정과 모델의 판단 근거를 로그로 남겨, 나중에 개발자가 검토할 수 있도록 합니다. 예를 들어 "원인 분석 결과: A 함수 null 체크 부족 -> null 검사 추가 (GPT-4o)", "패치 적용 및 테스트 실패: 새로운 실패 발생, 롤백 수행" 등의 로그를 축적합니다. 이러한 로그는 FastAPI 엔드포인트로 조회하거나 파일로 저장하여 **에이전트 행동의 투명성**을 확보합니다.

### 6. 리팩토링 제안 및 품질 개선 (Refactor 에이전트)

Self-Improver 루프의 궁극적인 목표는 단순히 테스트를 통과하는 것뿐 아니라 **코드 품질과 유지보수성 향상**입니다. 따라서 모든 테스트가 통과하면 마지막으로 **리팩토링 제안 단계**를 추가합니다.

* **트리거**: 테스트 올 패스 후 또는 진입 시 AnalysisResult.refactor\_needed=True로 표시된 경우에만 실행합니다. (불필요한 경우 건너뜀)
* **역할**: GPT-4o에게 최종 코드를 검토시키고, **잠재적 리팩토링 포인트**를 찾아내게 합니다. 예를 들어 "중복 코드 통합", "함수 추출", "이해하기 어려운 변수명 개선" 등의 제안을 생성할 수 있습니다.
* **처리**:

  * 주요 대상 파일 또는 모듈의 코드를 GPT-4o에 제공하고, 아키텍처 관점에서 개선할 부분을 묻습니다. Prompt:

    ```
    시스템: 당신은 시니어 소프트웨어 엔지니어입니다. 아래 코드가 모든 테스트를 통과했지만, 더 개선할 부분이 있는지 검토하세요.
    사용자 입력:
    코드: {전체 코드 혹은 모듈 요약}
    ```

    ```
    요구: 리팩토링이 필요하거나 개선할 부분이 있다면, 항목별로 제안하세요. 변경 시 기존 기능은 유지해야 합니다.
    ```
  * GPT-4o는 여러 가지 제안을 bullet 형식으로 반환할 수 있습니다. 예:

    1. "함수 `X`가 너무 길고 중복 로직을 포함 – 유틸 함수로 분리 권장"
    2. "클래스 `Y`의 책임이 모호 – 단일 책임 원칙에 맞게 두 클래스로 분리 고려"
  * 이러한 제안을 **개발자에게 보고**하거나, 원한다면 자동 적용도 가능합니다. 그러나 자동 적용 시에도 각 제안에 대해 다시 한 번 테스트를 돌려야 하므로, 기본값은 **수동 검토용 제안 리스트 출력**으로 합니다.
  * FastAPI 엔드포인트를 통해 이 제안을 확인하거나 저장할 수 있게 합니다. 예를 들어 `/self-improve/refactor_suggestions` 요청 시 JSON으로 제안 목록을 반환하도록 구현합니다.
* **모델 선택**: 코드 구조 조언에는 가장 능력이 좋은 **GPT-4o**를 사용합니다. 경우에 따라 GPT-o3-pro가 충분할 수 있으나, 소스 코드 전체 맥락 이해와 최적 개선 방안 도출에는 GPT-4o의 신뢰도가 높습니다.
* **출력**: 리팩토링 제안 리스트 (자연어 설명 + 관련 코드 위치). 이 결과도 Pydantic 모델로 표현해 볼 수 있습니다:

  ```python
  class RefactorSuggestion(BaseModel):
      description: str
      target: Optional[str]  # 대상 파일/함수/라인 등
  ```

  여러 개의 제안을 `List[RefactorSuggestion]` 형태로 묶어 반환합니다.

以上이 Self-Improver 루프의 전체 사이클 구현 지침입니다. 이 루프는 **LangGraph 그래프 에이전트**로서 상태를 유지하며 자동으로 수행되지만, FastAPI 등을 통해 **명시적으로 트리거**해야 합니다. 예를 들어, 개발자가 웹 UI나 CLI에서 "/self-improve/start"를 호출하면 이 그래프 에이전트를 실행하여 순차적으로 동작하도록 구현할 수 있습니다.

## 온톨로지 기반 추천 시스템 강화

온톨로지 기반 추천 시스템은 \*\*지식 그래프(ontology)\*\*와 **벡터 임베딩 기반 의미 검색**을 결합하여, 사용자 질의에 대한 심도 있는 질의응답과 맥락성 높은 추천을 제공하는 기능입니다. 이를 위해 Pydantic으로 정의한 **온톨로지 데이터 모델**과 **ChromaDB 벡터 데이터베이스**를 활용합니다. 또한 LangGraph를 통해 질의응답 과정을 하나의 에이전트 워크플로우로 구성할 수 있습니다. 아래에 구현 전략을 단계별로 제시합니다.

### 1. 온톨로지 데이터 모델링 (Pydantic 기반)

**역할**: 지식 그래프의 노드와 관계를 표현하는 데이터 구조를 정의합니다. Pydantic을 사용하여 데이터 모델을 선언하면, 검증과 직렬화가 쉬워지고 FastAPI와 통합하기도 용이합니다.

* **온톨로지 구성**: 도메인에 따라 여러 종류의 노드(예: 개념, 문서, 코드 스니펫 등)가 있을 수 있지만, 우선 일관된 **기본 노드 모델**을 정의합니다. 예시:

  ```python
  from pydantic import BaseModel, Field
  from typing import List, Optional

  class OntologyNode(BaseModel):
      id: str = Field(..., description="노드의 고유 ID")
      type: str = Field(..., description="노드 유형 (예: 개념, 질문, 코드, etc.)")
      name: str = Field(..., description="노드 이름 또는 제목")
      description: str = Field(..., description="노드에 대한 설명 또는 내용")
      related_ids: List[str] = Field([], description="연관된 다른 노드의 ID 목록")
  ```

  * `id`: 노드를 유일하게 식별하는 문자열.
  * `type`: 온톨로지 내 분류 타입. 필요에 따라 `"Concept"`, `"Resource"`, `"Issue"`, `"Solution"` 등 도메인 타입을 정의합니다.
  * `name`과 `description`: 각 노드의 핵심 정보. 특히 `description`은 노드의 내용을 서술하는 텍스트로, 벡터 임베딩의 입력으로 사용됩니다.
  * `related_ids`: 그래프 상의 링크를 나타냅니다. 해당 노드와 의미적으로 또는 계층적으로 연결된 다른 노드들의 ID 리스트로 저장합니다. (양방향 그래프라면 A 노드의 related\_ids에 B가 있으면 B에도 A를 추가하거나, 별도의 Edge 리스트로 관리 가능합니다.)
* **확장성**: 필요한 경우 BaseModel을 상속하여 세분화된 모델을 만들 수 있습니다. 예를 들어 `class ConceptNode(OntologyNode)`나 `class CodeSnippetNode(OntologyNode)`를 정의해 추가 필드를 가질 수 있습니다. 그러나 초기 구현에서는 단일 OntologyNode로도 충분하며, 추후 타입별 필드 추가가 쉽게 이루어질 수 있도록 구조를 잡습니다.
* **데이터 저장**: 실제 데이터 저장은 간단히 Python dict 혹은 DB로 할 수 있습니다. 예를 들어 `ontology_nodes: Dict[str, OntologyNode]` 딕셔너리에 노드를 저장하고 ID로 접근할 수 있게 합니다. 규모가 커지면 Neo4j나 RDF 스토어 검토도 가능하지만, 1인 개발자의 로컬 도구이므로 경량 접근으로 시작합니다.
* **예시**:

  ```python
  ontology_nodes = {}
  node = OntologyNode(id="CONCEPT_001", type="Concept", name="Large Language Model", description="거대 언어 모델(LLM)에 대한 개념", related_ids=[])
  ontology_nodes[node.id] = node
  ```

### 2. ChromaDB 벡터 검색 통합

**역할**: 각 노드의 설명 등 텍스트를 임베딩 벡터로 변환하여 \*\*벡터 데이터베이스(ChromaDB)\*\*에 저장하고, 의미 기반 유사 검색을 수행합니다. ChromaDB를 통해 사용자의 자연어 질의에 가장 관련 높은 노드들을 검색할 수 있습니다.

* **임베딩 생성**: 우선 적절한 **임베딩 모델**을 선택합니다. 오픈소스로는 `SentenceTransformers`의 사전학습 모델을 활용할 수 있습니다 (예: `"all-MiniLM-L6-v2"` 등). 임베딩 생성을 위해 `chromadb.utils.embedding_functions`에서 제공하는 헬퍼를 사용합니다:

  ```python
  import chromadb
  from chromadb.utils import embedding_functions

  CHROMA_DATA_PATH = "chroma_data/"  # 벡터DB 저장 경로
  embed_fn = embedding_functions.SentenceTransformerEmbeddingFunction(model_name="all-MiniLM-L6-v2")
  client = chromadb.PersistentClient(path=CHROMA_DATA_PATH)  # 영구 저장
  collection = client.create_collection(name="ontology", embedding_function=embed_fn)
  ```

  위 코드로 ChromaDB 클라이언트를 초기화하고 `"ontology"`라는 컬렉션을 생성합니다. PersistentClient를 사용하면 벡터 인덱스를 디스크에 유지하여 재시작 후에도 데이터를 복구할 수 있습니다. 개발 단계에서는 `chromadb.Client()`로 메모리 내 사용도 가능합니다.
* **벡터 저장**: 온톨로지 노드를 추가/갱신할 때마다 그 `description` 텍스트를 임베딩하여 컬렉션에 저장합니다. 예:

  ```python
  def add_node_to_chroma(node: OntologyNode):
      collection.add(documents=[node.description], 
                     metadatas=[{"name": node.name, "type": node.type}], 
                     ids=[node.id])
  ```

  여기서 metadata로 name과 type을 저장하여 나중에 결과 필터링이나 출력에 활용합니다. `ids`는 노드의 ID를 사용하므로, 나중에 검색 결과에서 해당 ID를 통해 ontology\_nodes 딕셔너리에서 원본 노드 객체를 찾을 수 있습니다.
* **검색 쿼리**: 사용자의 자연어 질문이나 키워드를 입력받으면, 그 문장을 임베딩하여 컬렉션에서 최근접 임베딩들을 찾습니다. ChromaDB의 `collection.query`를 사용합니다:

  ```python
  query_text = "사용자의 질문 또는 검색어"
  results = collection.query(query_texts=[query_text], n_results=5)
  ```

  이렇게 하면 `results` 딕셔너리에 유사도가 가장 높은 5개의 항목 정보가 반환됩니다. `results["documents"]`에는 각 결과 노드의 description 텍스트, `results["ids"]`에는 각 결과의 ID 리스트, `results["distances"]`에는 유사도(거리) 값들이 들어있습니다. 예를 들어 ChromaDB는 기본적으로 cosine 거리를 사용하며, 거리값이 0에 가까울수록 유사도가 높습니다. 검색 결과로부터 우리는 노드 ID들을 추출하여 해당 OntologyNode 객체들을 가져옵니다.
* **메타데이터 활용**: 필요하면 쿼리에 메타데이터 필터를 적용할 수 있습니다. 예를 들어 특정 type의 노드만 찾고 싶다면 `where={"type": "Concept"}` 같은 필터를 `query()`에 전달합니다. 현재 시나리오에서는 특별한 필터 요구가 없으므로 기본 설정으로 진행합니다.

### 3. 지식 그래프 링크 탐색 (Network Traversal)

**역할**: 벡터 검색으로 얻은 초기 결과를 풍부하게 하기 위해, **온톨로지 그래프의 연결 관계**를 활용합니다. 즉, 우선순위 후보로 식별된 노드와 직접 연관된 노드들을 함께 고려함으로써 답변/추천의 깊이를 높입니다.

* **직접 링크 추가**: 검색 결과 노드들(`top_nodes`)에 대해, 각 노드의 `related_ids`를 확인하고 해당 ID들의 노드도 후보 세트에 추가합니다. 이때 너무 많은 노드를 추가하지 않도록, 각 결과 노드당 1\~2개 정도의 중요한 linked node만 고려하거나, 중복된 경우 중복 제거합니다. 예컨대:

  ```python
  related_candidates = set()
  for node in top_nodes:
      for rid in node.related_ids:
          related_candidates.add(ontology_nodes[rid])
  # top_nodes 리스트에 related_candidates를 병합 (중복 ID 제외)
  ```

  이렇게 하면 초기 벡터기반으로 고른 노드들의 **인접 노드**들이 후보군에 포함됩니다. 만약 지식 그래프가 계층적(예: 챕터-섹션 관계)이라면 부모/자식 노드도 함께 고려될 수 있습니다.
* **확장 링크 (옵션)**: 필요에 따라 2-hop까지 확장할 수 있지만, 너무 멀어지면 잡음이 늘어나므로 1-hop까지만 활용하는 것을 권장합니다.
* **우선순위 결정**: 최종 후보군에는 벡터 유사도 높은 노드들과, 그 주변 노드들이 섞여있습니다. 이들을 추천 답변에 활용할 때 **우선순위**를 정해야 합니다. 간단한 전략으로, **벡터 유사도 점수에 일정 가중치를 준 순위**를 매길 수 있습니다. 예:

  * 기본 유사도 점수를 100점 만점으로 환산 (Chroma distance를 유사도로 변환하여 0\~100).
  * 만약 노드가 **직접 검색 결과**였다면 그 점수를 그대로 사용.
  * **링크를 통해 추가된 노드**라면 해당 링크를 따라온 원본 노드의 점수에서 일정 값을 감산하여 사용 (예: 원본노드 점수 - 10).
  * 이렇게 하면 검색 결과에 나왔던 노드들이 상위에, 링크로 온 노드들이 그 다음 순위에 오르게 됩니다. 이 단순 방식을 적용하거나, 필요 시 LLM에게 중요도를 평가하도록 할 수도 있습니다.
* **모델 활용**: 링크 탐색 자체에는 LLM이 필요 없지만, 만약 노드들 중 어떤 것이 답변에 더 적합한지 **평가**가 필요하면 GPT-o4-mini에게 각 후보 노드의 `name`이나 `description`을 보여주고 "질문에 가장 관련 높은 순으로 정렬"하도록 물을 수도 있습니다. 그러나 이러한 추가 호출 없이도, 임베딩 점수와 그래프 연결로 충분히 품질을 높일 수 있습니다.

### 4. 의미 기반 질의응답 생성 (QA 에이전트)

**역할**: 최종 선정된 정보들을 활용하여 사용자 질의에 대한 **응답 생성** 또는 **추천 목록 제공**을 수행합니다. 여기서 LLM이 다시 투입되어 다수의 지식 조각을 맥락 있게 묶어 자연어 답변을 구성합니다.

* **입력**: 사용자 질의(자연어 문장), 및 앞서 수집된 관련 **노드들의 정보 목록**. 노드 정보에는 이름, 설명, (필요시 타입 등 메타데이터) 그리고 해당 노드 간의 관계가 포함됩니다.
* **프롬프트 구성**: GPT-4o 모델을 사용하여 응답을 생성합니다 (응답의 정확성과 문맥 통합을 위해 최고 성능 모델 권장). 프롬프트에는 다음을 포함합니다:

  * 사용자 질문을 그대로 제시: `"질문: ___"`
  * 관련 지식 베이스 정보 나열:

    * 단순 나열보다는 약간 가공된 형태로 제시합니다. 예를 들어, 각 노드를 하나의 문단으로 요약:

      ```
      [정보1] {노드1.name}: {노드1.description}
      [정보2] {노드2.name}: {노드2.description}
      ...
      ```
    * 만약 노드 간에 직접적인 관계가 중요하다면, "노드1과 노드2는 연결됨" 같은 메모를 덧붙일 수도 있습니다.
  * 시스템 역할로: `"당신은 지식 그래프 기반 조언자입니다. 주어진 정보를 활용하여 질문에 답하세요. 필요하면 정보를 종합하고, 연결 관계도 고려하세요."`
  * 최종 사용자에게 전달할 답변을 한국어로 생성하도록 명시합니다.
* **응답 생성**: GPT-4o는 위 프롬프트를 토대로, 관련 정보들을 종합한 답변을 생성합니다. 예컨대 사용자가 "LLM이 무엇인가요?" 물었다면, 관련 노드로 "Large Language Model" 개념 노드와 예시들이 검색되고, GPT-4o는 이를 참고하여 **"LLM은 방대한 양의 데이터로 학습된 언어 모델로서 사람의 언어와 유사하게 텍스트를 이해하고 생성할 수 있습니다..."** 같은 답변을 만들어냅니다. 여러 노드에서 온 정보를 하나로 합치는 과정에서 사실 관계가 어긋나지 않도록, 프롬프트 지시에 사실에 충실할 것을 강조합니다.
* **인용/출처 (선택)**: 내부적으로 노드 출처를 추적해 두었다가, 답변에 출처 표시를 할 수도 있습니다. 하지만 이는 1인 사용 환경에서는 필수는 아닙니다. 필요하면 노드 name이나 id를 각 문장 끝에 각주처럼 붙여줄 수 있습니다.
* **모델 최적화**: 간단한 질문은 GPT-o3-pro로도 답할 수 있지만, **다수의 정보 통합**이나 **추론적 질문** (예: "X와 Y 개념의 차이점은?")의 경우 GPT-4o의 활용이 안전합니다. 비용을 고려하여, 질문 길이나 복잡도에 따라 동적으로 모델을 선택하도록 할 수 있습니다 (ex: 질문 토큰 수가 작고 간단하면 o3-pro, 아니면 4o).
* **출력**: 최종 사용자에게 전달할 답변 텍스트. FastAPI를 통해 응답을 JSON으로 줄 경우, \`{"answer": "..."} 형태로 감싸서 반환합니다.

### 5. 추천 결과 제공 및 알고리즘 개선

**역할**: 질문에 대한 직접 답변 외에도, 관련 정보를 **추천 목록** 형태로 제공하거나, 알고리즘을 지속 개선합니다.

* **연관 항목 추천**: 사용자가 질의한 주제와 관련하여 추가로 볼 만한 노드들을 추천할 수 있습니다. 예컨대 "LLM이 무엇인가요?"라는 질문에 답하면서, 추가로 **"관련 개념: Transformer, GPT 모델 역사"** 등을 추천 리스트로 제시합니다. 구현방법:

  * 앞서 선정된 후보 노드 중, 답변에 직접 사용되지 않았지만 유용할만한 것들을 추려서 리스트업합니다.
  * 또는 노드의 `related_ids`를 통해 주변 지식을 찾아 제안합니다. 예: LLM 노드에 연결된 "Transformer" 노드나 "자연어 처리" 상위 개념 노드 등을 추천합니다.
  * 이러한 추천 리스트는 FastAPI 응답에 별도 필드(`related_items`)로 담거나, 답변 끝부분에 추가 정보 형태로 덧붙일 수 있습니다.
* **FastAPI 엔드포인트**: `/query` 혹은 `/ask` GET/POST 엔드포인트를 만들어, 질의 문자열을 받고 위의 검색+QA 과정을 거쳐 답변과 추천을 반환하도록 구현합니다. 예:

  ```python
  @app.get("/ask")
  def ask_question(q: str):
      answer_text, related = qa_agent.answer(q)  # answer는 텍스트, related는 추천 항목 리스트
      return {"question": q, "answer": answer_text, "related": related}
  ```

  이렇게 하면 사용자는 `q` 파라미터로 질의를 보내고, AI가 생성한 답변과 관련 항목들을 받을 수 있습니다.
* **추천 알고리즘 개선 고려사항**:

  * **피드백 루프**: 사용자가 어느 추천을 클릭하거나, 만족/불만 피드백을 주는 경우, 이를 수집하여 추후 순위 조정에 활용합니다. (현재는 1인 사용자이므로 간단히 선호도에 따라 related\_ids를 동적으로 추가하거나, 메타데이터에 중요도를 기록하는 정도를 생각할 수 있습니다.)
  * **지속적 온톨로지 확장**: AI 에이전트가 새로운 정보를 얻었을 때 자동으로 지식 그래프를 확장하도록 할 수 있습니다. 예를 들어 사용자의 새로운 질문이 기존 그래프에 없는 개념이라면, LLM이 해당 개념을 설명하는 노드를 생성해서 ontology\_nodes와 ChromaDB에 추가하는 기능도 향후 고려합니다. 이때 Pydantic 모델 검증을 거쳐 노드가 적절한지 확인하고 추가합니다.
  * **임베딩 업데이트**: 노드 내용이 수정되거나 새로 추가되면 반드시 `collection.add` 또는 `collection.update`를 호출하여 벡터 DB를 동기화해야 합니다. 또한 일정 기간마다 (혹은 노드 수가 많아지면) 벡터 재색인을 고려합니다.
  * **하이브리드 랭킹**: 벡터 유사도 + 그래프 중심성 등을 조합한 점수 산정으로 더 정교한 추천이 가능합니다. 예를 들어 **PageRank** 같은 알고리즘으로 그래프에서 중요 노드를 미리 계산해 두고, 추천 시 중요도가 높은 노드를 약간 우대하는 방식입니다. 현재 단계에서는 과하지만, 노드가 수백 개 이상으로 늘어나면 적용을 검토합니다.
  * **성능 최적화**: ChromaDB는 내부적으로 효율적인 인덱싱을 하지만, 질의당 LLM 호출이 병목일 수 있습니다. 그러므로 캐싱 전략도 생각합니다. 동일한 질의에 대한 이전 답변이 있으면 재생성하지 않고 캐시를 제공하거나, 노드 조합이 동일한 경우 답변을 약간 변형하는 정도로 빠르게 응답하는 등의 개선을 들 수 있습니다.

### 6. LangGraph 에이전트를 통한 QA 워크플로우 (선택 사항)

위 질의응답 과정을 LangGraph의 상태 그래프로 정의하면, 보다 구조적인 질의 처리 파이프라인을 구현할 수 있습니다. 예를 들어:

* 노드: **QueryParser** – 입력 질의를 분류/이해 (예: 질문 유형 파악). 간단한 문자열 처리나 패턴 매칭으로도 가능하지만, 복잡한 경우 GPT-o4-mini를 사용해 "질문 유형" 등을 분류할 수 있습니다.
* 노드: **SemanticRetriever** – 질의를 받아 ChromaDB에서 유사 노드 검색. (도구로 구현 가능)
* 노드: **LinkExpander** – 검색 결과를 받아 관련 노드 확장. (파이썬 함수로 구현)
* 노드: **AnswerComposer** – 최종 후보 노드들과 질의를 받아 답변 생성. (GPT-4o 모델 사용)
* 노드: **OutputFormatter** – 답변을 사용자에게 반환할 형식으로 정리 (JSON 구성 등, 경량 처리).

LangGraph로는 위 노드들을 직렬로 연결하고 필요에 따라 조건부 분기(예: 질의가 "추천" 형태이면 답변 대신 목록만 제공 등)를 넣을 수 있습니다. 다만, 현재 시스템에서는 비교적 단순한 QA이므로 필수는 아니며, 추후 복잡한 대화 관리나 사용자 맥락 유지가 필요해지면 도입을 고려합니다.

## 결론 및 요약

본 구현 계획서는 Palantir.Zip 프로젝트의 핵심 기능 두 가지 – **Self-Improver 루프**와 **온톨로지 기반 추천 시스템** – 를 고도화하기 위한 체계적인 방안을 제시했습니다. 각 기능은 역할별 에이전트와 모듈로 명확히 분리되어 있으며, Python 기반 오픈소스 기술 스택(FastAPI, LangGraph, ChromaDB, Pydantic, Pytest 등)을 활용하여 현실적인 구현이 가능하도록 설계되었습니다.

요약하면:

* **Self-Improver 루프**: GPT 모델들을 다단계로 활용한 자동 코드 개선 사이클을 구현합니다. 테스트 실패 원인을 AI가 분석하고, 코드를 수정하며, 반복 시도하되 롤백과 중단 조건으로 안전성을 담보합니다. LangGraph의 **조건부 순환 루프**를 통해 실패 시 재시도, 일정 횟수 초과 시 종료를 제어합니다. 최종적으로 모든 테스트를 통과하면 코드 품질 향상을 위한 리팩토링 제안까지 제공합니다.
* **온톨로지 추천 시스템**: Pydantic으로 정의된 지식 그래프를 ChromaDB 벡터DB와 통합하여, **의미 기반 질의응답**과 **연관 항목 추천**을 구현합니다. 자연어 질문에 대해 벡터 유사도로 관련 지식을 찾고, 그래프 링크로 확장한 정보를 GPT 모델이 통합하여 답변을 생성합니다. FastAPI 엔드포인트를 통해 질의에 대한 답변과 추가 추천을 전달하며, 향후 사용자 피드백을 반영한 추천 알고리즘 개선도 고려합니다.

모든 구성 요소는 **모듈화**되어 있어, 예를 들어 모델 교체(GPT-업데이트 등)나 새로운 에이전트 추가(예: 보안 분석 에이전트 등) 시에도 시스템에 영향이 최소화되도록 설계되었습니다.

이 문서를 바탕으로 에이전트에게 단계별 구현을 맡기면, 각 단계마다 명확한 목표와 예시 코드, 그리고 테스트 방안(Pytest 기반)이 제시되어 있으므로 실제 개발을 효율적으로 진행할 수 있을 것입니다. 필요한 경우 각 단계 완료 후 Pytest로 검증하여 신뢰성을 확보하고, 전체 루프 및 추천 기능의 통합 테스트도 수행합니다.

以上을 통해 Palantir.Zip 플랫폼의 핵심 기능이 한층 강화되어, 1인 개발자의 생산성을 극대화하는 **자동화된 AI 개발 파트너**로서 동작할 것을 기대합니다.
